{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D50ekWXjEl_S"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f7c203ffaa1"
      },
      "source": [
        "### Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e66b2f6d36f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!sudo apt install -q jq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8_93ZrVJkPY"
      },
      "source": [
        "### Restart current runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDezbO9oJkPY",
        "outputId": "ee154b84-eada-4893-98c0-12afa2c2b069"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP1Qa2JAJkPa"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment.\n",
        "\n",
        "This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6ZGaZlxP9L0"
      },
      "source": [
        "### Set Google Cloud project\n",
        "\n",
        "To get started using Vertex AI, the organizers will provide you with these parameters to connect to the API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8IivOG5SqY6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define project information\n",
        "PROJECT_ID = \"Project_id\"  # @param {type:\"string\"}\n",
        "LOCATION = \"Region\"  # @param {type:\"string\"}\n",
        "\n",
        "# Import libraries\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "854fbf388e2b"
      },
      "source": [
        "## Use the Gemini 2.0 Flash model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eeb063ac6d4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.0-flash\"\n",
        "API_HOST = f\"{LOCATION}-aiplatform.googleapis.com\"\n",
        "\n",
        "os.environ[\"API_ENDPOINT\"] = (\n",
        "    f\"{API_HOST}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/{MODEL_ID}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZZUVBSzc0cR"
      },
      "source": [
        "## Text generation\n",
        "\n",
        "The `generateContent` method can handle a wide variety of use cases, including multi-turn chat and multimodal input, depending on what the underlying model supports. In this example, you send a text prompt and request the model response in text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1979afec8834",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e767328-045e-4a25-c73f-8bb5a6bf7195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sky appears blue due to a phenomenon called **Rayleigh scattering**. Here's the breakdown:\n",
            "\n",
            "*   **Sunlight and its Colors:** Sunlight, which appears white, is actually made up of all the colors of the rainbow. Each color has a different wavelength, with violet and blue having the shortest wavelengths, and red having the longest.\n",
            "\n",
            "*   **The Atmosphere and Molecules:** The Earth's atmosphere is filled with tiny particles of nitrogen and oxygen molecules, as well as other small particles.\n",
            "\n",
            "*   **Rayleigh Scattering:** When sunlight enters the atmosphere, it collides with these tiny air molecules. This collision causes the light to scatter in different directions. The amount of scattering depends on the wavelength of the light. Shorter wavelengths (blue and violet) are scattered much more strongly than longer wavelengths (red and orange).\n",
            "\n",
            "*   **Why Blue and Not Violet?** While violet light is scattered more than blue light, our eyes are more sensitive to blue. Also, the sun emits slightly less violet light than blue light. Therefore, we perceive the sky as blue rather than violet.\n",
            "\n",
            "*   **Sunrise and Sunset:** During sunrise and sunset, the sunlight has to travel through a much greater distance through the atmosphere to reach our eyes. This longer path means that most of the blue light is scattered away before it reaches us. The longer wavelengths, like red and orange, are able to pass through with less scattering, which is why we see those colors.\n",
            "\n",
            "**In short:** Blue light is scattered more by the atmosphere than other colors, making the sky appear blue to our eyes.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "curl -X POST \\\n",
        "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  https://${API_ENDPOINT}:generateContent \\\n",
        "  -d '{\n",
        "    \"contents\": {\n",
        "      \"role\": \"USER\",\n",
        "      \"parts\": { \"text\": \"Why is the sky blue?\" },\n",
        "    },\n",
        "    \"generation_config\": {\n",
        "      \"response_modalities\": \"TEXT\",\n",
        "     },\n",
        "  }' 2>/dev/null >response.json\n",
        "\n",
        "jq -r \".candidates[].content.parts[].text\" response.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e56BV7PH9t8"
      },
      "source": [
        "### Model parameters\n",
        "\n",
        "Every prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. You can experiment with different model parameters to see how the results change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px8hSHhiH9t8",
        "tags": [],
        "outputId": "090030b8-adca-4fcd-e55a-ce476b253c63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The lighthouse keeper, Silas, was a man woven from the sea itself. His skin was tanned and weathered like driftwood, his eyes the grey-green of a storm-tossed wave. He'd spent thirty years tending the beacon on the jagged, isolated Isle of Aethel, a lonely sentinel against the unforgiving Atlantic.\n",
            "\n",
            "Silas wasn't lonely, though. He had the gulls for company, the rhythmic crash of the waves, and the stories whispered on the wind. He knew the sea's moods intimately, its gentle caress and its furious rage. He knew the names of the constellations, the migratory patterns of the birds, and the secrets hidden in the tide pools.\n",
            "\n",
            "One day, a storm unlike any he'd ever witnessed descended upon Aethel. The wind howled like a banshee, tearing at the lighthouse walls. Waves, mountains of black water, crashed against the tower, threatening to swallow it whole. Silas, his face grim, fought to keep the lamp burning, its beam a defiant finger pointing into the abyss.\n",
            "\n",
            "Amidst the chaos, he saw something bobbing in the churning water. A small, wooden crate, battered and broken, but still afloat. Driven by a primal urge, Silas braved the storm, securing a rope and hauling the crate onto the narrow balcony.\n",
            "\n",
            "Inside, nestled amongst seaweed and broken planks, was a creature unlike any he'd ever seen. It was small, no bigger than his hand, with iridescent scales that shimmered like captured rainbows. It had large, luminous eyes that held an ancient wisdom, and delicate, feathery fins. It was a mermaid, a baby mermaid, lost and terrified.\n",
            "\n",
            "Silas, a man who had never known tenderness, felt a surge of protectiveness. He wrapped the creature in a soft cloth, whispering soothing words he hadn't spoken in years. He fed it drops of fresh water and tiny slivers of fish. He named her Coralia, after the coral reefs he'd only seen in books.\n",
            "\n",
            "For weeks, Coralia lived in the lighthouse. Silas became her guardian, her teacher, her friend. He told her stories of the land, of the stars, of the world beyond the sea. He learned about her world, the underwater kingdoms, the songs of the whales, the secrets of the deep.\n",
            "\n",
            "As Coralia grew, she yearned for the ocean. Silas knew he couldn't keep her forever. He knew she belonged to the sea.\n",
            "\n",
            "One clear, moonlit night, Silas carried Coralia to the edge of the island. The sea was calm, reflecting the stars like a million diamonds. He held her close, his heart aching with a bittersweet sorrow.\n",
            "\n",
            "\"It's time, little one,\" he whispered, his voice thick with emotion. \"Go home.\"\n",
            "\n",
            "Coralia looked at him, her luminous eyes filled with gratitude and affection. She reached out a tiny hand and touched his weathered cheek, leaving a trail of shimmering scales. Then, with a flick of her tail, she slipped into the water and disappeared into the depths.\n",
            "\n",
            "Silas stood there for a long time, watching the waves. He knew he would never see Coralia again, but he also knew that a part of her would always remain with him. The sea, which had always been his companion, now held a new meaning, a new connection.\n",
            "\n",
            "The lighthouse keeper, once a solitary figure, was no longer alone. He carried the memory of a mermaid, a secret whispered on the wind, a reminder that even in the darkest storms, there is always hope, always beauty, and always the possibility of finding connection in the most unexpected places. And sometimes, the greatest treasures are not found in the depths of the sea, but in the depths of the heart.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "curl -X POST \\\n",
        "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  https://${API_ENDPOINT}:generateContent \\\n",
        "  -d '{\n",
        "    \"contents\": {\n",
        "      \"role\": \"USER\",\n",
        "      \"parts\": [\n",
        "        {\"text\": \"Tell me a story.\"}\n",
        "      ]\n",
        "    },\n",
        "    \"generation_config\": {\n",
        "      \"temperature\": 0.2,\n",
        "      \"top_p\": 0.1,\n",
        "      \"top_k\": 16,\n",
        "      \"max_output_tokens\": 2048,\n",
        "      \"candidate_count\": 1,\n",
        "      \"stop_sequences\": []\n",
        "    },\n",
        "    \"safety_settings\": {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "    }\n",
        "  }' 2>/dev/null >response.json\n",
        "\n",
        "jq -r \".candidates[].content.parts[].text\" response.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4-XhmPn_Pb-"
      },
      "source": [
        "### Chat\n",
        "\n",
        "The Gemini API supports natural multi-turn conversations and is ideal for text tasks that require back-and-forth interactions.\n",
        "\n",
        "Specify the `role` field only if the content represents a turn in a conversation. You can set `role` to one of the following values: `user`, `model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqSQSK-K-KVU",
        "tags": [],
        "outputId": "9b7f4aa6-bc96-4c46-b0a9-55881ff65b90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alright, let's get down to business! To give you the most relevant answer, I need a little more context.  What are we meeting about?  What kind of business are we talking about here?\n",
            "\n",
            "For example, are we:\n",
            "\n",
            "*   **Starting a project?** We might need to define goals and assign tasks.\n",
            "*   **Planning an event?** We could discuss venue, date, and budget.\n",
            "*   **Having a general chat?** We could talk about anything!\n",
            "*   **Troubleshooting a problem?** We'd need to define the issue clearly.\n",
            "*   **Working on a software project?** Perhaps we should discuss user stories.\n",
            "*   **Running a meeting for a company?** Perhaps we need to ratify some agenda.\n",
            "\n",
            "Once I know the context, I can help you determine the most important first step. Give me some more information!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "curl -X POST \\\n",
        "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  https://${API_ENDPOINT}:generateContent \\\n",
        "  -d '{\n",
        "    \"contents\": [\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"parts\": [\n",
        "          { \"text\": \"Hello\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"role\": \"model\",\n",
        "        \"parts\": [\n",
        "          { \"text\": \"Hello! I am glad you could both make it.\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"parts\": [\n",
        "          { \"text\": \"So what is the first order of business?\" }\n",
        "        ]\n",
        "      }\n",
        "    ]\n",
        "  }' 2>/dev/null >response.json\n",
        "\n",
        "jq -r \".candidates[].content.parts[].text\" response.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3g5n23lDtsN"
      },
      "source": [
        "## Multimodal input\n",
        "\n",
        "Gemini is a multimodal model that supports adding image and video in text or chat prompts for a text response.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTfL2DDch4Lp"
      },
      "source": [
        "### Download an image from Google Cloud Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmtWSNLtJ7oD",
        "tags": [],
        "outputId": "dc7da2ea-11c8-4ebe-819c-37a032712f04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg...\n",
            "/ [1 files][ 17.4 KiB/ 17.4 KiB]                                                \n",
            "Operation completed over 1 objects/17.4 KiB.                                     \n"
          ]
        }
      ],
      "source": [
        "! gsutil cp \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\" ./image.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlyyaPgmhpyv"
      },
      "source": [
        "### Generate text from a local image\n",
        "\n",
        "Specify the [base64](https://en.wikipedia.org/wiki/Base64) encoding of the image or video to include inline in the prompt and the `mime_type` field. The supported [MIME types](https://en.wikipedia.org/wiki/Media_type) for images include `image/png` and `image/jpeg`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uqZ-RWdtdit",
        "tags": [],
        "outputId": "d32d98ba-7ffc-4862-fedf-04c44cf2a14f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yes, the image shows a cat. It's a tabby cat with a striped coat.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "# Encode image data in base64\n",
        "image_file=\"image.jpg\"\n",
        "if [[ -f \"$image_file\" ]]; then\n",
        "  if command -v base64 &> /dev/null; then\n",
        "    # base64 is available\n",
        "    if [[ \"$(uname -s)\" == \"Darwin\" ]]; then\n",
        "      # macOS -b 0 to avoid line wrapping\n",
        "      data=$(base64 -b 0 -i \"$image_file\")\n",
        "    else\n",
        "      # Linux -w 0 to avoid line wrapping\n",
        "      data=$(base64 -w 0 \"$image_file\")\n",
        "    fi\n",
        "  else\n",
        "    echo \"Error: base64 command not found.\"\n",
        "    exit 1\n",
        "  fi\n",
        "else\n",
        "  echo \"Error: Image file '$image_file' not found.\"\n",
        "  exit 1\n",
        "fi\n",
        "\n",
        "curl -X POST \\\n",
        "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  https://${API_ENDPOINT}:generateContent \\\n",
        "  -d \"{\n",
        "      'contents': {\n",
        "        'role': 'USER',\n",
        "        'parts': [\n",
        "          {\n",
        "            'text': 'Is it a cat?'\n",
        "          },\n",
        "          {\n",
        "            'inline_data': {\n",
        "              'data': '${data}',\n",
        "              'mime_type':'image/jpeg'\n",
        "            }\n",
        "          }\n",
        "        ]\n",
        "       }\n",
        "    }\" 2>/dev/null >response.json\n",
        "\n",
        "jq -r \".candidates[].content.parts[].text\" response.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKr-BklmhjgP"
      },
      "source": [
        "### Generate text from an image on Google Cloud Storage\n",
        "\n",
        "Specify the Cloud Storage URI of the image to include in the prompt. The bucket that stores the file must be in the same Google Cloud project that's sending the request. You must also specify the `mime_type` field. The supported image MIME types include `image/png` and `image/jpeg`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43pQE3_z3OjG",
        "tags": [],
        "outputId": "b4db6795-3789-4d55-c7fc-b27254f6591d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here's a description of the image:\n",
            "\n",
            "**Overall Impression:**\n",
            "\n",
            "The image shows a tabby cat standing in the snow. The cat is the main subject and is in focus, while the snowy background is slightly blurred.\n",
            "\n",
            "**Cat's Appearance:**\n",
            "\n",
            "*   **Coat:** The cat has a classic tabby coat pattern, with dark brown or black stripes on a lighter brown background.\n",
            "*   **Eyes:** The cat has yellow or golden eyes.\n",
            "*   **Pose:** The cat is standing with one paw slightly raised, as if it's about to take a step. It's looking directly at the viewer with a curious or alert expression.\n",
            "*   **Build:** The cat appears to be of average build, neither overly thin nor overweight.\n",
            "\n",
            "**Background:**\n",
            "\n",
            "*   The background is entirely snow-covered.\n",
            "*   There are some subtle textures and variations in the snow, suggesting it might be a path or a field.\n",
            "*   The background is out of focus, which helps to emphasize the cat as the main subject.\n",
            "\n",
            "**Overall Tone:**\n",
            "\n",
            "The image has a natural and slightly cold feel due to the snow. The cat's alert expression adds a touch of curiosity and liveliness to the scene.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "curl -X POST \\\n",
        "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  https://${API_ENDPOINT}:generateContent \\\n",
        "  -d '{\n",
        "    \"contents\": {\n",
        "      \"role\": \"USER\",\n",
        "      \"parts\": [\n",
        "        {\n",
        "          \"text\": \"Describe this image\"\n",
        "        },\n",
        "        {\n",
        "          \"file_data\": {\n",
        "            \"mime_type\": \"image/png\",\n",
        "            \"file_uri\": \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\"\n",
        "          }\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    \"generation_config\": {\n",
        "      \"temperature\": 0.2,\n",
        "      \"top_p\": 0.1,\n",
        "      \"top_k\": 16,\n",
        "      \"max_output_tokens\": 2048,\n",
        "      \"candidate_count\": 1,\n",
        "      \"stop_sequences\": []\n",
        "    },\n",
        "    \"safety_settings\": {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "    }\n",
        "  }' 2>/dev/null >response.json\n",
        "\n",
        "jq -r \".candidates[].content.parts[].text\" response.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVF4vHuBOD8N"
      },
      "source": [
        "### Generate text from a video file\n",
        "\n",
        "Specify the Cloud Storage URI of the video to include in the prompt. The bucket that stores the file must be in the same Google Cloud project that's sending the request. You must also specify the `mime_type` field. The supported MIME types for video include `video/mp4`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8kS5p0l_uHE",
        "tags": [],
        "outputId": "56593c8b-dd72-41ce-f014-2cb275c02ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Okay, here's the answer to your questions based on the video:\n",
            "\n",
            "*   **Profession of the main person:** Photographer\n",
            "*   **Main features of the phone highlighted:** Video Boost with Night Sight (to make the quality even better)\n",
            "*   **City recorded in:** Tokyo\n",
            "\n",
            "I hope this answers your questions!\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "curl -X POST \\\n",
        "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  https://${API_ENDPOINT}:generateContent \\\n",
        "  -d \\\n",
        "'{\n",
        "    \"contents\": {\n",
        "      \"role\": \"USER\",\n",
        "      \"parts\": [\n",
        "        {\n",
        "          \"text\": \"Answer the following questions using the video only. What is the profession of the main person? What are the main features of the phone highlighted? Which city was this recorded in?\"\n",
        "        },\n",
        "        {\n",
        "          \"file_data\": {\n",
        "            \"mime_type\": \"video/mp4\",\n",
        "            \"file_uri\": \"gs://github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4\"\n",
        "          }\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  }' 2>/dev/null >response.json\n",
        "\n",
        "jq -r \".candidates[].content.parts[].text\" response.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37223c8e3133"
      },
      "source": [
        "### Code Execution\n",
        "\n",
        "The Gemini API code execution feature enables the model to generate and run Python code and learn iteratively from the results until it arrives at a final output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cebe2cd31c1",
        "tags": [],
        "outputId": "805c73fe-0fbc-45ec-d1dc-40b21506a0cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"text\": \"Okay, I can do that. First, I'll calculate the 20th Fibonacci number, and then I'll find the nearest palindrome.\\n\\n\"\n",
            "}\n",
            "{\n",
            "  \"executableCode\": {\n",
            "    \"language\": \"PYTHON\",\n",
            "    \"code\": \"def fibonacci(n):\\n    if n <= 0:\\n        return 0\\n    elif n == 1:\\n        return 1\\n    else:\\n        a, b = 0, 1\\n        for _ in range(2, n + 1):\\n            a, b = b, a + b\\n        return b\\n\\nfib_20 = fibonacci(20)\\nprint(f'{fib_20=}')\\n\"\n",
            "  }\n",
            "}\n",
            "{\n",
            "  \"codeExecutionResult\": {\n",
            "    \"outcome\": \"OUTCOME_OK\",\n",
            "    \"output\": \"fib_20=6765\\n\"\n",
            "  }\n",
            "}\n",
            "{\n",
            "  \"text\": \"The 20th Fibonacci number is 6765. Now, let's find the nearest palindrome to 6765. I'll check palindromes above and below it.\\n\\nThe closest palindrome smaller than 6765 is 6776 in reverse which is 6776. Let's see if there's one closer. We can try generating some palindromes around 6765. Numbers of the form 6XX6 and 6XXX6 should be considered.\\n\\nLet's check 6666 and 6886, which are clearly closer. Then, we'll find the absolute differences to 6765.\\n\\n\"\n",
            "}\n",
            "{\n",
            "  \"executableCode\": {\n",
            "    \"language\": \"PYTHON\",\n",
            "    \"code\": \"fib_20 = 6765\\npalindrome1 = 6666\\npalindrome2 = 6868\\n\\ndiff1 = abs(fib_20 - palindrome1)\\ndiff2 = abs(fib_20 - palindrome2)\\n\\nprint(f'{diff1=}')\\nprint(f'{diff2=}')\\n\\nif diff1 < diff2:\\n  print(f'{palindrome1=} is closer')\\nelse:\\n  print(f'{palindrome2=} is closer')\\n\\n\"\n",
            "  }\n",
            "}\n",
            "{\n",
            "  \"codeExecutionResult\": {\n",
            "    \"outcome\": \"OUTCOME_OK\",\n",
            "    \"output\": \"diff1=99\\ndiff2=103\\npalindrome1=6666 is closer\\n\"\n",
            "  }\n",
            "}\n",
            "{\n",
            "  \"text\": \"The nearest palindrome to 6765 is 6666, which is 99 away from 6765.\\n\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "curl -X POST \\\n",
        "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  https://${API_ENDPOINT}:generateContent \\\n",
        "  -d '{\n",
        "  \"contents\": {\n",
        "    \"role\": \"user\",\n",
        "    \"parts\": {\n",
        "      \"text\": \"Calculate 20th fibonacci number. Then find the nearest palindrome to it.\"\n",
        "    }\n",
        "  },\n",
        "  \"tools\": [\n",
        "      {\"code_execution\": {},}\n",
        "  ]\n",
        "}' 2>/dev/null >response.json\n",
        "\n",
        "jq -r \".candidates[].content.parts[]\" response.json"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "conda-base-py",
      "name": "workbench-notebooks.m129",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel) (Local) (Local)",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}